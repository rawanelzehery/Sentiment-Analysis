{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The same task as Lab 1 except using `RNNs`**\n",
    "\n",
    "**Watch out!<br>\n",
    "Preproceesing here is a a bit different**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "labeled datasset collected from twitter\n",
    "\n",
    "**Objective**\n",
    "classify tweets containing hate speech from other tweets. <br>\n",
    "0 -> no hate speech <br>\n",
    "1 -> contains hate speech <br>\n",
    "\n",
    "**Total Estimated Time = 60-90 Mins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Load the `clean data` preprocessed in `Lab 1`, then handle it to be used with `RNNs`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check duplicates \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop id \n",
    "df.drop(columns = 'id' , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates \n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation between # , :) and label !\n",
    "# problems : #  @user  emojii  punctuate  url_validate \n",
    "# want to check if sentenses had hate speech or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_at(txt):\n",
    "    clean_txt = re.sub('@user', '',txt )\n",
    "    return clean_txt\n",
    "#checked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(txt):\n",
    "    regex = r\"[!\\\"\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`{\\|}~]\"\n",
    "    subst = \"\"\n",
    "    clean_txt = re.sub(regex, subst, txt, 0, re.MULTILINE)\n",
    "    return clean_txt\n",
    "#checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pun(txt):\n",
    "    regex = r\"[!\\\"\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`{\\|}~]\"\n",
    "    subst = \"\"\n",
    "    clean_txt = re.sub(regex, subst, txt, 0, re.MULTILINE)\n",
    "    return clean_txt\n",
    "#checked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_english(txt):\n",
    "    clean_txt = re.sub(r\"[^a-zA-Z0-9#]\", ' ',txt )\n",
    "    return clean_txt\n",
    "#checked  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_url(text):\n",
    "    pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    return bool(pattern.search(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "31956    False\n",
       "31957    False\n",
       "31958    False\n",
       "31959    False\n",
       "31961    False\n",
       "Name: tweet, Length: 29530, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].apply(contains_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(txt):\n",
    "    clean_txt1 = remove_at(txt)\n",
    "    clean_txt2 = remove_pun(clean_txt1)\n",
    "    clean_txt3 = remove_non_english(clean_txt2)\n",
    "    clean_txt4 = clean_txt3.lower()\n",
    "    return clean_txt4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(wrangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "    Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in corpus: 29486\n",
      "Unique tags in corpus: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique words in corpus:\", df['tweet'].nunique())\n",
    "print(\"Unique tags in corpus:\", df['label'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29486"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = list(set(df['tweet'].values))\n",
    "#words.append(\"ENDPAD\")\n",
    "num_tweets = len(tweets)\n",
    "num_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(set(df['label'].values))\n",
    "num_labels = len(labels)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i + 1 for i, w in enumerate(tweets)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'label'\n",
    "feature = 'tweet'\n",
    "X = df[feature]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X , y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize our training data\n",
    "tokenizer = Tokenizer(num_words=num_tweets, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Encode training data sentences into sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# Get max training sequence length\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "\n",
    "# Pad the training sequences\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29486"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word2idx)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([    \n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 64),\n",
    "    tf.keras.layers.SimpleRNN(64),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[tf.keras.metrics.Precision(thresholds=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "155/155 [==============================] - 6s 40ms/step - loss: 0.0444 - precision: 0.0679 - val_loss: 0.2667 - val_precision: 0.0695\n",
      "Epoch 2/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0176 - precision: 0.0679 - val_loss: 0.3043 - val_precision: 0.0695\n",
      "Epoch 3/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0144 - precision: 0.0679 - val_loss: 0.3353 - val_precision: 0.0695\n",
      "Epoch 4/10\n",
      "155/155 [==============================] - 6s 38ms/step - loss: 0.0073 - precision: 0.0679 - val_loss: 0.3406 - val_precision: 0.0695\n",
      "Epoch 5/10\n",
      "155/155 [==============================] - 6s 41ms/step - loss: 0.0054 - precision: 0.0679 - val_loss: 0.3866 - val_precision: 0.0695\n",
      "Epoch 6/10\n",
      "155/155 [==============================] - 6s 40ms/step - loss: 0.0066 - precision: 0.0679 - val_loss: 0.5115 - val_precision: 0.0695\n",
      "Epoch 7/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0084 - precision: 0.0679 - val_loss: 0.3569 - val_precision: 0.0695\n",
      "Epoch 8/10\n",
      "155/155 [==============================] - 6s 39ms/step - loss: 0.0049 - precision: 0.0679 - val_loss: 0.3776 - val_precision: 0.0695\n",
      "Epoch 9/10\n",
      "155/155 [==============================] - 6s 38ms/step - loss: 0.0037 - precision: 0.0679 - val_loss: 0.4077 - val_precision: 0.0695\n",
      "Epoch 10/10\n",
      "155/155 [==============================] - 6s 40ms/step - loss: 0.0024 - precision: 0.0679 - val_loss: 0.4019 - val_precision: 0.0695\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded, y_train, epochs=10, batch_size=128,\n",
    "                    validation_data=(test_padded, y_test), \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 1s 4ms/step - loss: 0.3932 - precision: 0.0688\n",
      "Test Loss: 0.3932141065597534\n",
      "Test Percision: 0.0687532052397728\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_per = model.evaluate(test_padded, y_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Percision: {}'.format(test_per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSTM\n",
    "lstm_bi = tf.keras.models.Sequential([    \n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_bi.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[tf.keras.metrics.Precision(thresholds=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "619/619 [==============================] - 33s 53ms/step - loss: 0.0029 - precision_1: 0.0679 - val_loss: 0.2884 - val_precision_1: 0.0688\n",
      "Epoch 2/10\n",
      "619/619 [==============================] - 35s 57ms/step - loss: 0.0041 - precision_1: 0.0679 - val_loss: 0.2962 - val_precision_1: 0.0688\n",
      "Epoch 3/10\n",
      "619/619 [==============================] - 37s 60ms/step - loss: 0.0020 - precision_1: 0.0679 - val_loss: 0.2663 - val_precision_1: 0.0688\n",
      "Epoch 4/10\n",
      "619/619 [==============================] - 34s 55ms/step - loss: 6.8451e-04 - precision_1: 0.0679 - val_loss: 0.3854 - val_precision_1: 0.0688\n",
      "Epoch 5/10\n",
      "619/619 [==============================] - 38s 61ms/step - loss: 5.0617e-04 - precision_1: 0.0679 - val_loss: 0.4081 - val_precision_1: 0.0688\n",
      "Epoch 6/10\n",
      "619/619 [==============================] - 34s 55ms/step - loss: 3.3562e-04 - precision_1: 0.0679 - val_loss: 0.3849 - val_precision_1: 0.0688\n",
      "Epoch 7/10\n",
      "619/619 [==============================] - 34s 55ms/step - loss: 2.1745e-04 - precision_1: 0.0679 - val_loss: 0.4331 - val_precision_1: 0.0688\n",
      "Epoch 8/10\n",
      "619/619 [==============================] - 33s 53ms/step - loss: 1.0535e-04 - precision_1: 0.0679 - val_loss: 0.5539 - val_precision_1: 0.0688\n",
      "Epoch 9/10\n",
      "619/619 [==============================] - 33s 54ms/step - loss: 4.0880e-04 - precision_1: 0.0679 - val_loss: 0.4662 - val_precision_1: 0.0688\n",
      "Epoch 10/10\n",
      "619/619 [==============================] - 40s 65ms/step - loss: 1.7285e-04 - precision_1: 0.0679 - val_loss: 0.5623 - val_precision_1: 0.0688\n"
     ]
    }
   ],
   "source": [
    "history = lstm_bi.fit(train_padded, y_train, epochs=10,\n",
    "                    validation_data=(test_padded, y_test), \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 3s 11ms/step - loss: 0.5623 - precision_1: 0.0688\n",
      "Test Loss: 0.5622667670249939\n",
      "Test Percision: 0.0687532052397728\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_per = lstm_bi.evaluate(test_padded, y_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Percision: {}'.format(test_per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results & Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have noticed the difference between on simple rnn and lstm  on accuracy but not percision (i used the percision cause the unbalanced data but i'm not sure) ?!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
